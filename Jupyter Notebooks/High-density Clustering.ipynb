{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary modules\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import netCDF4 as nc\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "from scipy.spatial import distance_matrix\n",
    "from matplotlib import cm as cm\n",
    "from matplotlib.collections import PatchCollection\n",
    "from matplotlib.patches import Polygon\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import MeanShift\n",
    "from scipy.spatial.distance import cdist\n",
    "import math\n",
    "import debacl as dbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the file path for loading, data file is under the same dir with the notebook\n",
    "filename=\"20121015_00_ecmwf_ensemble_forecast.PRESSURE_LEVELS.EUR_LL10.120.pl.nc\"\n",
    "foldername=\"ECWMF Datasets\"\n",
    "filepath=os.path.join(os.path.dirname(os.getcwd()),foldername,filename)\n",
    "\n",
    "# read the raw data and extract the needed data\n",
    "# exrtact the value of Geopotential under the pressure of 500 hPA in the certain\n",
    "Pressure_Levels_data = nc.Dataset(filepath,\"r\")\n",
    "g = 9.80655\n",
    "# get all the dimension value\n",
    "nd_1,nd_2,nd_3,nd_4,nd_5 = Pressure_Levels_data.variables['Geopotential_isobaric'][:].shape\n",
    "# get the necessary raw data\n",
    "Geopotential_Isobaric_500 = Pressure_Levels_data.variables['Geopotential_isobaric'][0,:,7,:,:]/g\n",
    "# reshape the dataset into form of (51,41*101)\n",
    "Geopotential_Isobaric_500_reshaped = np.reshape(Geopotential_Isobaric_500,(nd_2, nd_4 * nd_5))\n",
    "# prepare the longitude and latitude value for contour\n",
    "longitude = Pressure_Levels_data['lon'][:]\n",
    "latitude = Pressure_Levels_data['lat'][:]\n",
    "(lon, lat) = np.meshgrid(longitude, latitude)\n",
    "\n",
    "# use PCA to reduce dimensions under the condition of reaching 80% of all the member infomation\n",
    "exp_var = 0\n",
    "n_pc = 0\n",
    "while exp_var < 0.8:\n",
    "    n_pc = n_pc + 1\n",
    "    pca = PCA(n_components = n_pc)\n",
    "    pca.fit(Geopotential_Isobaric_500_reshaped)\n",
    "    exp_var = sum(pca.explained_variance_ratio_)\n",
    "\n",
    "# get the transformed raw data in the dimension-reduced space    \n",
    "pca_transformed_data = pca.transform(Geopotential_Isobaric_500_reshaped)\n",
    "\n",
    "#get the time variable\n",
    "times=Pressure_Levels_data.variables[\"time\"]\n",
    "#get the time number\n",
    "arrDateEnd=nc.num2date(times[:],units=times.units)\n",
    "#get the time in date format\n",
    "dateEndDate = datetime.date(arrDateEnd[0]).strftime(\"%d %b %Y\")\n",
    "dateEndMin = datetime.date(arrDateEnd[0]).strftime(\"%H:%M\")\n",
    "dateStart=datetime.date(arrDateEnd[0])-timedelta(hours=120)\n",
    "dateStartDate=dateStart.strftime(\"%d %b %Y\")\n",
    "dateStartMin=dateStart.strftime(\"%H:%M\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gauKern(point,h,isocontourSet):\n",
    "    PI=math.pi\n",
    "    p=point.shape[0]\n",
    "\n",
    "    n=len(isocontourSet)\n",
    "    sum=0\n",
    "    \n",
    "    for i in range(n):\n",
    "        diff=point-isocontourSet[i]\n",
    "        temp =np.exp(-np.sum(diff**2)/2*(h**2))/(np.sqrt(2*PI)*(h**p))\n",
    "        sum=sum+temp\n",
    "        \n",
    "    return sum/n "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_limit(number):\n",
    "    if number<0:\n",
    "        temp=np.abs(number)\n",
    "        c=1  \n",
    "        while (temp//10)!=0:\n",
    "            temp=temp/10\n",
    "            c+=1\n",
    "        number=-1*(-1*number+10**(c-1))\n",
    "    else:\n",
    "        temp=number\n",
    "        c=1  \n",
    "        while (temp//10)!=0:\n",
    "            temp=temp/10\n",
    "            c+=1\n",
    "        number=number+10**(c-1)\n",
    "        \n",
    "    return number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pointSet(isocontourSet,interval):\n",
    "    maxnum=isocontourSet.max()\n",
    "    minnum=isocontourSet.min()\n",
    "    maxlim=get_limit(maxnum)\n",
    "    minlim=get_limit(minnum)\n",
    "    \n",
    "    dim=isocontourSet.shape[1]\n",
    "    oneDim=np.linspace(minlim,maxlim,interval)\n",
    "    \n",
    "    multiDim=[oneDim for i in range(dim)]\n",
    "    grid=np.meshgrid(*multiDim)\n",
    "    \n",
    "    reshape=[np.reshape(grid[j],(interval**dim)) for j in range(dim)]\n",
    "    \n",
    "    result= np.vstack(reshape).T\n",
    "    return resultlt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_Cluster_Label(data,bandwidth):\n",
    "    density=[gauKern(data[i],0.001,data) for i in range(len(data))]\n",
    "    for index,value in enumerate(density):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.762089325705055e-28"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gauKern(pca_transformed_data[0],600,pca_transformed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_Area_Data_General(rawdataToCalc,lon_rawdataToCalc,lat_rawdataToCalc,bottomLeft,topRight):\n",
    "    #def Get_Subgrid(lon_rawdataToCalc,lat_rawdataToCalc,bottomLeft,topRight):\n",
    "        lonStart=(np.abs(lon_rawdataToCalc - bottomLeft[0])).argmin()\n",
    "        lonEnd=(np.abs(lon_rawdataToCalc - topRight[0])).argmin()\n",
    "        latStart=(np.abs(lat_rawdataToCalc - bottomLeft[1])).argmin()\n",
    "        latEnd=(np.abs(lat_rawdataToCalc - topRight[1])).argmin()\n",
    "\n",
    "        areaData=rawdataToCalc[:,latEnd:latStart+1,lonStart:lonEnd+1]\n",
    "        return areaData\n",
    "\n",
    "def Reshape_New_Data(areaData):\n",
    "    dim1,dim2,dim3=areaData.shape\n",
    "    reshapedData=np.reshape(areaData,(dim1,dim2*dim3))\n",
    "    return reshapedData\n",
    "\n",
    "def PCA_Run(reshapedData):\n",
    "    exp_var = 0\n",
    "    n_pc = 0\n",
    "    while exp_var < 0.8:\n",
    "        n_pc = n_pc + 1\n",
    "        pca = PCA(n_components = n_pc)\n",
    "        pca.fit(reshapedData)\n",
    "        exp_var = sum(pca.explained_variance_ratio_)\n",
    "        \n",
    "    return pca\n",
    "\n",
    "from scipy.stats import scoreatpercentile as sap\n",
    "from statsmodels.sandbox.nonparametric import kernels\n",
    "from collections import Counter\n",
    "\n",
    "def _select_sigma(X):\n",
    "#    normalize = norm.ppf(.75) - norm.ppf(.25)\n",
    "    normalize = 1.349\n",
    "#    IQR = np.subtract.reduce(percentile(X, [75,25],\n",
    "#                             axis=axis), axis=axis)/normalize\n",
    "    IQR = (sap(X, 75) - sap(X, 25))/normalize\n",
    "    return np.minimum(np.std(X, axis=0, ddof=1), IQR)\n",
    "\n",
    "def bw_scott(x, kernel=kernels.Gaussian):\n",
    "    A = _select_sigma(x)\n",
    "    n = len(x)\n",
    "    return 1.059 * A * n ** (-0.2)\n",
    "\n",
    "def meanshift(sig,dataset, bandwidth):\n",
    "    meanshift = MeanShift(bandwidth=bandwidth)  \n",
    "    meanshift.fit(dataset)\n",
    "    labels = meanshift.labels_\n",
    "    dicLabels=Counter(labels)\n",
    "    innerSigModeNum=0\n",
    "    innerOutlierModeNum=0\n",
    "\n",
    "    for i in dicLabels:\n",
    "        if dicLabels[i] >= sig:\n",
    "            innerSigModeNum = innerSigModeNum + 1\n",
    "        else:\n",
    "            innerOutlierModeNum = innerOutlierModeNum + 1\n",
    "            \n",
    "    return innerSigModeNum,innerOutlierModeNum,dicLabels,labels\n",
    "\n",
    "def bandwidth_selection(dataset,bandwidth):    \n",
    "    loop=True\n",
    "    significanceLower = int(len(dataset)*0.3)\n",
    "    outlierUpper = 2\n",
    "\n",
    "    sigModeNum=0\n",
    "    outlierModeNum=0\n",
    "    n=1\n",
    "\n",
    "    innerSigModeNum,innerOutlierModeNum,dicLabels,labels=meanshift(significanceLower,dataset,bandwidth)\n",
    "    if innerOutlierModeNum>outlierUpper:\n",
    "        while loop==True:\n",
    "            print(\"bandwidth: {0}, labels: {1}, exicution times: {2}\".format(bandwidth,dicLabels,n))\n",
    "            n=n+1\n",
    "            bandwidth=bandwidth+1\n",
    "            innerSigModeNum,innerOutlierModeNum,dicLabels,labels=meanshift(significanceLower,dataset,bandwidth)\n",
    "            if innerOutlierModeNum<outlierUpper:\n",
    "                loop == False\n",
    "                break\n",
    "    else:\n",
    "        while loop==True:\n",
    "            print(\"bandwidth: {0}, labels: {1}, exicution times: {2}\".format(bandwidth,dicLabels,n))\n",
    "            n=n+1\n",
    "            bandwidth=bandwidth-1\n",
    "            innerSigModeNum,innerOutlierModeNum,dicLabels,labels=meanshift(significanceLower,dataset,bandwidth)\n",
    "            if innerOutlierModeNum>=outlierUpper:\n",
    "                print(\"bandwidth: {0}, labels: {1}, exicution times: {2}\".format(bandwidth,dicLabels,n))\n",
    "                n=n+1\n",
    "                loop == False\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import netCDF4 as nc\n",
    "import numpy as np\n",
    "#get the file path for loading, data file is under the same dir with the notebook\n",
    "filename=\"20121017_12_ecmwf_forecast.PRESSURE_LEVELS.EUR_LL015.036.pl.nc\"\n",
    "foldername=\"ECWMF Datasets\"\n",
    "filepath=os.path.join(os.path.dirname(os.getcwd()),foldername,filename)\n",
    "syn = nc.Dataset(filepath,\"r\")\n",
    "#syn.variables\n",
    "longitude1 = syn['lon'][:]\n",
    "latitude1 = syn['lat'][:]\n",
    "(lon1, lat1) = np.meshgrid(longitude1, latitude1)\n",
    "syndata =syn.variables['Geopotential_isobaric'][:]/9.8\n",
    "syndataiso1 = syndata[0,:,0,:,:]\n",
    "syndataiso2 = syndata[0,:,1,:,:]\n",
    "syndataiso3 = syndata[0,:,2,:,:]\n",
    "secData1  = Get_Area_Data_General(syndataiso1,longitude1,latitude1,[0,40],[20,60])\n",
    "reshapeData1=Reshape_New_Data(secData1)\n",
    "PCA_1=PCA_Run(reshapeData1)\n",
    "transformedData1=PCA_1.transform(reshapeData1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 0 1 1 0 1 2 2 0 2 1 0 1 2 1 2 0 0 2 0 1 0 0 0 1 0 2 0 0 1 0 0 0 0 0 2\n",
      " 0 1 1 0 0 2 0 0 0 2 1 0 0 0]\n",
      "Counter({0: 27, 2: 12, 1: 12})\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import estimate_bandwidth as bwe\n",
    "from collections import Counter\n",
    "meanshift = MeanShift(bandwidth=114)\n",
    "meanshift.fit(transformedData1)\n",
    "print(meanshift.labels_)\n",
    "print(Counter(meanshift.labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bandwidth: 114, labels: Counter({0: 27, 2: 12, 1: 12}), exicution times: 1\n"
     ]
    }
   ],
   "source": [
    "bandwidth_selection(transformedData1,120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
